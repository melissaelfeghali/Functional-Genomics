---
title: "Final Project - Functional Genomics"
author: "Melissa El Feghali"
date: "12/9/2020"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true 
    theme: darkly
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# First Quality Control Check

FastQC version 0.11.7

We need to make sure that the number of lines in each of the files is the same. 

```{bash}
# We use cat to print out content and wc -l to count the number of lines

time cat ~/Desktop/Data/392_1.fastq.gz | wc -l
```

```{bash}
time cat ~/Desktop/Data/392_2.fastq.gz | wc -l
```

# Generate FastQC html report

```{bash engine.opts='-l'}
# time fastqc ~/Desktop/Data/392_1.fastq.gz
```
real	3m29.118s
user	4m11.118s
sys	  0m5.203s

```{bash engine.opts='-l'}
# time fastqc ~/Desktop/Data/392_2.fastq.gz
```
real	4m3.383s
user	4m48.640s
sys	0m6.144s

## Illumina Version 

![Illumina Version](/Users/melissa.elfeghali/GitLab/BIF425_Fall20_ElFeghali_Melissa/Final_Project/Illumina_version.png)
Illumina version 1.9 was used. 

## Bad quality tiles 

To check for the tile quality, we check the "Per tile sequence quality" section in the FastQC html report. The plot shows the deviation from the average quality for each tile. The colors are on a cold to hot scale, with cold colors being positions where the quality was at or above the average for that base in the run, and hotter colors indicate that a tile had worse qualities than other tiles for that base. We notice that our plots are all blue, which indicates that there are no tiles with bad quality. 

![Per tile sequence quality](/Users/melissa.elfeghali/GitLab/BIF425_Fall20_ElFeghali_Melissa/Final_Project/Tile_quality.png)

# Trimming 

Trimmomatic version 0.39 

-jar executes a program encapsulated in a JAR archive. The first argument after it is the path to the .jar file
PE indicates Pair-End reads 
-trimlog followed by output path to .log file 
input path to 392_1.fastq.gz 
input path to 392_2.fastq.gz 
output path to 392_1.fastq.gz trimmed paired file 
output path to 392_1.fastq.gz trimmed unpaired file
output path to 392_2.fastq.gz trimmed paired file
output path to 392_2.fastq.gz trimmed unpaired file
ILLUMINACLIP:path_to_adapter_file:maximum_allowed_mismatch_between_read_and_adapterSequence:palidrom_clip_threshold_used_only_in_PE:minimum_required_score_between_adapter_and_read
LEADING: minimum required quality to keep a leading 5'
TRAILING: minimum required quality to keep a trailing 3'
SLIDINGWINDOW:positions_to_read:average_required_quality_of_positions
MINLEN: minimum read length

To choose which adapter file to use we look at the "Adapter content" plot generated by the fastqc report.

![Adapter Content](/Users/melissa.elfeghali/GitLab/BIF425_Fall20_ElFeghali_Melissa/Final_Project/Adapter_content.png)
```{bash}
# time java -jar /Users/melissa.elfeghali/Desktop/BIF/Courses/BIF425_FuntionalGenomics/NGS_WholeExome_Pipeline/Tools/Trimmomatic-0.39/trimmomatic-0.39.jar PE -threads 10 -trimlog 392.log 392_1.fastq.gz 392_2.fastq.gz 392_1_trimmed_paired.fastq.gz 392_1_trimmed_unpaired.fastq.gz 392_2_trimmed_paired.fastq.gz 392_2_trimmed_unpaired.fastq.gz  ILLUMINACLIP:/Users/melissa.elfeghali/Desktop/BIF/Courses/BIF425_FuntionalGenomics/NGS_WholeExome_Pipeline/Tools/Trimmomatic-0.39/adapters/TruSeq3-PE-2.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36
```
real    48m9.732s
user    57m47.705s
sys     38m54.901s

## Re-generate FastQC reports on paired output files.

```{bash engine.opts='-l'}
# time fastqc 392_1_trimmed_paired.fastq.gz
```
real    3m17.252s
user    4m0.749s
sys     0m4.628s

```{bash engine.opts='-l'}
# time fastqc 392_2_trimmed_paired.fastq.gz
```
real    3m10.125s
user    3m52.562s
sys     0m4.208s

## Validation of trimming plots {.tabset .tabset-fade .tabset-pills}

### Before trimming 

```{r}
library(parallel)
library(fastqcr)
```

```{r}
library(tictoc)
tic("Raw plots")
qc_raw <- mclapply("~/Desktop/Data/392_1_fastqc.zip", qc_read, mc.cores = detectCores()) 
toc()
```
```{r}
qc_raw[[1]]$summary
```
We notice WARN: warning (slightly abnormal) in the Adapter Content. 

### After trimming 

```{r}
tic("Trimmed plots")
qc_trimmed <- mclapply("~/Desktop/Data/392_1_trimmed_paired_fastqc.zip", qc_read, mc.cores = detectCores()) 
toc()
```
```{r}
qc_trimmed[[1]]$summary
```
We now have a PASS in the adapter content plot which indicates normal results. 

## Length remaining reads after trimming 

Before the trimming, the read length was 151. After trimming, the length of the remaining reads is between 36 and 151.

![Read length after trimming](/Users/melissa.elfeghali/GitLab/BIF425_Fall20_ElFeghali_Melissa/Final_Project/SequenceLength_trimming.png)
## Maximum average read phred score

```{r}
library(ShortRead)
tic("read fastq file")
r1 <- readFastq("~/Desktop/Data/392_1_trimmed_paired.fastq.gz")
toc()
```
read fastq file: 127.586 sec elapsed

The below function loops through all the reads, calculate their average phred score and output the maximum average read score. The function runs on subset of the file but takes too long on the entire file.
```{r}
# tic("Max average read phred score")
# 
# max_score <- 0
# for (i in 1:3000000){
#   quality_score <- as(quality(r1)[i], "matrix")[,]
#   avrg_score <- mean(quality_score)
#   if(avrg_score > max_score){
#     max_score <- avrg_score
#   }
# }
# 
# print(max_score)
# 
# toc()
```
Result: 37
Max average read phred score: 3477.578 sec elapsed

The below function loops through all the reads and outputs the first 1000 IDs of the reads with a certain average quality score. 
```{r}
find_readID_of_QS <- function(fastq_file, q_score)
{
  count <- 0
  for (i in 1:length(fastq_file)){
    if (count < 1000)
      {
        qual_score <- as(quality(fastq_file)[i], "matrix")[,]
        avg_qual_score <- mean(qual_score)
        if (avg_qual_score == q_score){
          count <- count + 1
          head_seq <- ShortRead::id(fastq_file)[i]
          print(paste0("Read ", count ," : ", head_seq))
          }
        }
      }
}
```

```{r}
tic("Find ID of reads with QS")
find_readID_of_QS(r1, 37)
toc()
```

## IDs of the 10 shortest read

The function below takes as argument a fastq file and a specified length and returns the first 10 reads with this length
```{r}
find_10_readLength <- function(fastq_file, l)
{
  avg <- c()
  count <- 0
  for (i in 1:length(fastq_file)){
    if (count < 10) {
      sequence_vector <- as.vector(sread(fastq_file)[i])
      length_sequence <- nchar(sequence_vector)
      if (length_sequence == l){
        count <- (count + 1)
        head_seq <- ShortRead::id(fastq_file)[i]
        print(paste0("Read ", count ," : ", head_seq))
      }
    }
  }
}
```

We already know that the shortest reads in our files are of length 36, thus we extract the first 10 reads with this length.

```{r}
tic("ID 10 shortest reads")
find_10_readLength(r1, 36)
toc()
```

# Download Reference Genome 

```{bash}
# create new folder to download the reference files 
# mkdir chr9

# time wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/chromosomes/chr9.fa.gz
```
real    0m48.506s
user    0m0.215s
sys     0m0.642s

```{bash}
# Unzip and concatenate chromosome and contig fasta files
# tar zvfx chr9.fa.gz
# time cat chr9/*.fa > hg38_chr9.fa
# rm -r /chr9
```
real    0m0.477s
user    0m0.017s
sys     0m0.436s

# Create Reference Index

-p index name 
-a index algorithm (bwtsw for long genomes)

```{bash}
# time bwa index -p hg38chr9bwaidx -a bwtsw hg38_chr9.fa
```
real    1m51.047s
user    1m49.238s
sys     0m1.729s

# Align to Reference Genome 

First, we need to get the read group information to pass it as an argument in the bwa command.
```{r}
tic("Read Group Info")

head <- as.vector(ShortRead::id(r1[1]))

labels <- c("instrument", "run_number", "flowcell_ID", "lane", "tile", "x_coordinate", "y_coordinate", "read", "is_filtered", "control_number", "index_seq")

a <- unlist(strsplit(head, split=":"))
split <- (strsplit(a[7], split=" "))
info <- unlist(append(a[1:6], split))
info <- append(info, a[8:10])

names(info) <- labels
info 

toc()
```

```{bash}
# time bwa mem -t 10 -R "@RG\tID:rg1\tSM:sample392\tPL:illumina\tLB:lib1\tPU:HNLHYDSXX:1:GCCGGACA+TGTAAGAG" hg38chr9bwaidx 392_1_trimmed_paired.fastq.gz 392_2_trimmed_paired.fastq.gz > 392_aln.sam
```
real    33m19.308s
user    334m37.912s
sys     2m57.247s

# Convert SAM to BAM 

Samtools Version: 1.11 (using htslib 1.11)

```{bash}
# time samtools view -Sb 392_aln.sam > 392_aln.bam
```
real    5m26.352s
user    5m16.177s
sys     0m9.280s

# Validate the BAM file

```{bash}
# time gatk ValidateSamFile -I 392_aln.bam -MODE SUMMARY
```
real    3m13.551s
user    3m14.667s
sys     0m1.804s

```{r}
# Sys.time() 
# "2020-12-11 00:06:30 EET"
```

# Sort the BAM file {.tabset .tabset-fade .tabset-pills}

```{bash}
# time gatk SortSam -I 392_aln.bam -O 392_sorted.bam -SORT_ORDER coordinate
```
real    4m10.427s
user    9m39.481s
sys     0m56.910s

## Reads Mapped 

```{r}
readxl::read_xlsx(path = "~/Desktop/BIF/Courses/BIF425_FuntionalGenomics/Exam_NGS_WholeExome/BitwiseFLAG.xlsx")
```
The bitflag 4 (or 0x4) indicates unmapped reads. Therefore, in order to find mapped reads, we use the -F INT which only includes reads with none of the FLAGS in INT present. We use the -c to count the number of mapped reads.

```{bash}
# time samtools view -c -F 0x4 392_sorted.bam     
```
real    0m36.059s
user    0m35.051s
sys     0m0.975s

Number of mapped reads : 7888808

To get the percentage of mapped reads, we need the total number of reads in the bam file
```{bash}
# time samtools view -c 392_sorted.bam
```
real    0m37.582s
user    0m36.785s
sys     0m0.767s

Total number of reads : 62004328

Percentage of mapped reads : 100*7888808/62004328 = 12.723 % 

## Average Mapping quality of mapped reads 

```{r}
tic("Average Mapping Quality")
m_qualities <- system("samtools view -F 0x4 ~/Desktop/Data/392_sorted.bam | cut -f 5", intern = TRUE)
mean(as.numeric(m_qualities))
toc()
```

Average mapping quality of mapped reads: 25.5996 (approx. 26)

## Reads without a pair complement

```{bash}
# time samtools view -c -F 0x1 392_sorted.bam     
```
real    0m36.853s
user    0m35.295s
sys     0m1.147s

Number of reads without a pair complement: 0

## Reads without insertions or deletions 

Deletions are marked with the letter ‘D’, and insertions with the letter 'I', in the CIGAR string for the alignment, which is shown in column 6. We use the cut -f 6 to get the info of the CIGAR string only. We use grep -v to give use the matches that do not include 'D' or 'I' and the -c to get the count.

```{bash}
# time samtools view 392_sorted.bam | cut -f 6 | grep -c -v -E 'I|D'
```
real    2m45.703s
user    3m51.914s
sys     0m7.168s

Number of reads without any insertion or deletion: 60829532

## Supplementary and secondary reads

Bitflag 0x800 corresponds to supplementary reads and 0x100 to secondary reads. Using 0x900 gives us both. 

```{bash}
# time samtools view -c -f 0x900 392_sorted.bam
```
real    0m36.419s
user    0m35.656s
sys     0m0.754s

Number of supplementary and secondary reads: 0

```{r}
# Sys.time() 
# "2020-12-11 01:49:46 EET"
```

# Mark Duplicates 

Index the genome again 
```{bash}
# time samtools faidx hg38_chr9.fa
```
real    0m0.479s
user    0m0.431s
sys     0m0.038s

PICARD can mark, and optionally remove, duplicate reads from sorted BAM files.The MarkDuplicates tool works by comparing sequences with identical 5’ positions. Reads with identical 5’ positions and identical sequences are marked as duplicates. 

GATK version 4.1.9.0

```{bash}
# time gatk MarkDuplicates -I 392_sorted.bam -O 392_dedup.bam -METRICS_FILE 392.metrics
```
real    2m41.980s
user    4m57.875s
sys     0m24.005s

```{bash}
# time gatk CreateSequenceDictionary -R hg38_chr9.fa -O hg38_chr9.dict
```
real    0m2.818s
user    0m8.187s
sys     0m0.551s

## Number of Duplicates 

```{bash}
# time samtools view -c -f 0x400 392_dedup.bam
```
real    0m37.833s
user    0m36.737s
sys     0m1.057s

Number of duplicates: 1372326

# Base Quality Score Recalibration

NGS provides estimates of base quality for each sequence based on Phred-scaled quality scores that reflect the likelihood that the base call is erroneous. The reported quality scores may be inaccurate as the result of systematic biases.

The base recalibration process involves two key steps: 
1- BaseRecalibrator tool builds a model of covariation based on the input data and a set of known variants, producing a re-calibartion file. 
2- ApplyBQSR tool adjusts the base quality scores in the data based on the model, producing a new BAM file. 

```{bash}
# time gatk BaseRecalibrator -I 392_dedup.bam -R hg38_chr9.fa --known-sites All_20180418.vcf.gz -O recal_data.table
```
real    5m44.479s
user    5m53.156s
sys     0m3.470s

Re-calibrate the base qualities of the input reads based on the re-calibration table produced by the BaseRecalibrator tool, and outputs a re-calibrated BAM or CRAM file. 

```{bash}
# time gatk ApplyBQSR -R hg38_chr9.fa -I 392_dedup.bam --bqsr-recal-file recal_data.table -O 392_recal.bam
```
real    12m58.481s
user    16m2.926s
sys     2m50.727s

We need to generate a second pass re-calibration table in order to analyze the biases in the re-calibrated data. 

```{bash}
# time gatk BaseRecalibrator -R hg38_chr9.fa -I 392_recal.bam --known-sites All_20180418.vcf.gz -O recal_secondpass.table
```
real    7m24.330s
user    7m33.112s
sys     0m4.912s

```{r}
# Sys.time()
# "2020-12-15 13:35:33 EET"
```

# Variant Calling {.tabset .tabset-fade .tabset-pills}

HaplotypeCaller can be used for single-sample or multiple-sample analysis. The program encounters a region showing signs of variation, it discards the existing mapping information and completely reassembles the reads in that region. 

Single-sample GVCF callings (intermediate output)
```{bash}
# time gatk HaplotypeCaller -R hg38_chr9.fa -I 392_recal.bam -O 392_recal.g.vcf.gz -ERC GVCF
```
real    59m48.558s
user    53m23.252s
sys     0m15.792s

-ERC GVCF : does certain corrections with respect to the reference genome.

Perform joint genotyping 
```{bash}
# time gatk GenotypeGVCFs -R hg38_chr9.fa -V 392_recal.g.vcf.gz -O final_392.vcf.gz
```
real    1m9.284s
user    0m51.014s
sys     0m1.388s

## Total Number of Variants 

```{bash}
# time gatk CountVariants -V final_392.vcf
```
real    0m3.610s
user    0m5.182s
sys     0m0.360s

Total Number of Variants: 62002

## Total Number of SNPS

```{bash}
# time gatk SelectVariants -R hg38_chr9.fa -V final_392.vcf --select-type-to-include SNP -O snps_392.vcf 
```
real    0m5.575s
user    0m8.511s
sys     0m0.479s

```{bash}
# time gatk CountVariants -V snps_392.vcf
```
real    0m2.556s
user    0m4.757s
sys     0m0.320s

Total Number of SNPS: 59227

## Total Number of INDELs

```{bash}
# time gatk SelectVariants -R hg38_chr9.fa -V final_392.vcf --select-type-to-include INDEL -O indels_392.vcf 
```
real    0m3.520s
user    0m5.492s
sys     0m0.343s

```{bash}
# time gatk CountVariants -V indels_392.vcf
```
real    0m2.405s
user    0m4.006s
sys     0m0.307s

Total Number of INDELs: 2755

## Genotype Fields

In order to differentiate between homozygotes wild type, heterozygotes and homozygotes mutant, we need to look at the Genotype fields in the VCF file. 

 0|0 or 0/0 : homozygote wild type 
 1|1 or 1/1 0r 2|2 or 2/2 or ... : homozygote mutant 
 
 if the numbers seperated by the / or | are different : heterozygote 
 
```{r}
library(vcfR)
tic("Read VCF File")
vcf = read.vcfR("~/Desktop/Data/final_392.vcf", verbose = FALSE )
toc()
```

```{r}
tic("Total numbers")

count_hetero <- 0
count_homo_wt <- 0
count_homo_mutant <- 0

for(i in 1:length(vcf@gt[,2])){
  genotype <- unlist(strsplit(vcf@gt[i,2], ":"))
  type <- genotype[1]
  if (type == "0|0" || type == "0/0"){
    count_homo_wt <- count_homo_wt + 1
  }
  else{
    type <- strsplit(type, c("|","/"))
    if (type$sample3921[1] == type$sample3921[3]){
      count_homo_mutant <- count_homo_mutant + 1
    }
    else{
      count_hetero <- count_hetero + 1
    }
  }
}

print(paste0("Total number of heterozygotes: ", count_hetero))
print(paste0("Total number of homozygotes wild type: ", count_homo_wt))
print(paste0("Total number of homozygotes mutant: ", count_homo_mutant))

toc()
```